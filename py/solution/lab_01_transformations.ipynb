{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 2: Image transformations with NumPy and OpenCV\n",
    "We will now use NumPy and OpenCV to transform an image by applying transformation matrices on homogeneous form.\n",
    "\n",
    "## 1. Eigen and homogeneous representations\n",
    "For different values of **t**, *&theta;* and **u**,\n",
    "\n",
    "use NumPy to define a 2D Euclidean transformation matrix\n",
    "\n",
    "  $\\mathbf{E} = \\begin{bmatrix}\\mathbf{R} & \\mathbf{t} \\\\\\mathbf{0} & 1\\end{bmatrix}$\n",
    "\n",
    "  where\n",
    "\n",
    "  $\\mathbf{R} =\n",
    "  \\begin{bmatrix}\n",
    "  \\cos \\theta & -\\sin \\theta \\\\\n",
    "  \\sin \\theta & \\cos \\theta\n",
    "  \\end{bmatrix}$\n",
    "\n",
    "  is the rotation matrix corresponding to a counterclockwise rotation with an angle *&theta;* about the origin, and\n",
    "\n",
    "  $\\mathbf{t} =\n",
    "  \\begin{bmatrix}\n",
    "  dx \\\\\n",
    "  dy \\\\\n",
    "  \\end{bmatrix}$\n",
    "\n",
    "  is the translation vector.\n",
    "\n",
    "Define a pixel\n",
    "\n",
    "  $\\mathbf{u} =\n",
    "  \\begin{bmatrix}\n",
    "  u \\\\\n",
    "  v \\\\\n",
    "  \\end{bmatrix}$\n",
    "\n",
    "  and obtain the transformed pixel $\\mathbf{u}_{trans}$ by computing the transformation using homogeneous coordinates\n",
    "\n",
    "$\\mathbf{\\tilde u}_{trans} = \\mathbf{E} \\mathbf{\\tilde u}$\n",
    "\n",
    "**Tips**:\n",
    "You might want to convert between degrees and radians, so see if you can find the appropriate values and functions in NumPy.\n",
    "Hint: [https://numpy.org/doc/stable/reference/routines.math.html](https://numpy.org/doc/stable/reference/routines.math.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# For convenience, we define two functions for converting a vector to homogeneous coordinates and back\n",
    "# If you are not at all familiar with the lambda, see e.g. https://www.w3schools.com/python/python_lambda.asp\n",
    "homogeneous = lambda x: np.append(x, [[1]], axis=0)\n",
    "hnormalized = lambda x: x[:-1]/x[-1]\n",
    "\n",
    "# TODO: Translation\n",
    "t = np.array([[0],[0]])\n",
    "\n",
    "# TODO: Rotation\n",
    "theta = np.radians(30)\n",
    "R = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta),  np.cos(theta)]\n",
    "])\n",
    "\n",
    "# TODO: Euclidean transformation that rotates and then translates\n",
    "E = np.block([\n",
    "    [R, t],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "# TODO: Perform the transformation on a pixel u.\n",
    "# Hint: What operator is used for matrix multiplication in NumPy?\n",
    "u = np.array([[100],[100]])\n",
    "u_transformed = hnormalized(E @ homogeneous(u))\n",
    "\n",
    "print(f\"Euclidean transformation E = \\n{E}\\n\")\n",
    "print(f\"Original pixel u = \\n{u}\\n\")\n",
    "print(f\"Transformed pixel u_transformed = \\n{u_transformed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Transform images\n",
    "<img src=\"../img-grid.png\" width=\"500\">\n",
    "\n",
    "We will now use the **E** matrix to transform the image above.\n",
    "\n",
    "Notice that you can use the grid and protractor to check your transformations.\n",
    "There are 100 pixels between each grid line, and you can check the rotation by recognizing which protractor line is parallel with the new y-axis.\n",
    "\n",
    "- Read the image using [cv2.imread()](https://docs.opencv.org/4.5.5/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56)\n",
    "- Perform the transformation using [cv2.warpPerspective()](https://docs.opencv.org/4.5.5/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87)\n",
    "- Try different transformations.\n",
    "- Try the *inverse* transformation (how can you easily compute that?).\n",
    "\n",
    "Hint: See the OpenCV Python tutorial, [Getting Started with Images](https://docs.opencv.org/4.5.5/db/deb/tutorial_display_image.html) (Click the `Python` button)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "# TODO: Read the image\n",
    "filename = '../img-grid.png'\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "# TODO: Perform transformation on the image\n",
    "\n",
    "# TODO: Repeat exercise 1 and create the transformation matrix E\n",
    "#t = None  #< Todo: repeat from step 1\n",
    "#R = None  #< Todo: repeat from step 1\n",
    "#E = None  #< Todo: repeat from step 1\n",
    "\n",
    "# img_size must be (cols, rows)\n",
    "img_size = img.shape[1::-1]\n",
    "img_trans_E = cv2.warpPerspective(img, E, img_size, flags=cv2.INTER_CUBIC)\n",
    "\n",
    "# Display the original and the transformed image\n",
    "axes = plt.subplots(1, 2)[1]\n",
    "ax1, ax2 = axes\n",
    "ax1.set_title('Original image')\n",
    "ax2.set_title('Transformed image')\n",
    "ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "ax2.imshow(cv2.cvtColor(img_trans_E, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "# TODO: Try different transformations (rotations and translations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 3. Composing transformations\n",
    "Have you noticed that the image is rotated around the upper left corner? Why is it so?\n",
    "\n",
    "We can rotate around the image center by first translating the origin to the center, rotating and then translate back by performing the opposite translation.\n",
    "We can compose these transformations to a single transformation by multiplying all corresponding transformation matrices together:\n",
    "\n",
    "$\\mathbf{E}_{composed} = \\mathbf{E}_{corner \\leftarrow center} \\; \\mathbf{E}_{rotate} \\; \\mathbf{E}_{center \\leftarrow corner}$\n",
    "\n",
    "- Rotate the image about its center by computing the composed transformation above.\n",
    "- Finally, try adding a scaling transformation (zoom) after the rotation. What kind of composed transformation do we obtain then?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "img = cv2.imread('../img-grid.png')\n",
    "\n",
    "# Todo: Compose transformations to rotate and scale around the centre of the image.\n",
    "#R = None  #< Todo: repeat from step 1\n",
    "theta = np.radians(60)\n",
    "R = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta),  np.cos(theta)]\n",
    "])\n",
    "\n",
    "# Compose transformations to rotate around the centre of the image:\n",
    "# First, find the pixel position of the image centre.\n",
    "c = np.array(img.shape[1::-1])/2\n",
    "print(f\"img size: {img.shape[:2]}, center pixel: {c}\\n\")\n",
    "\n",
    "# Define the translation that moves the origin to the image centre.\n",
    "E_translate_to_centre = np.eye(3)\n",
    "E_translate_to_centre[:2,2] = -c\n",
    "print(f\"E_translate_to_centre:\\n{E_translate_to_centre}\")\n",
    "\n",
    "# Use the same rotation as in 1.\n",
    "E_rotate = np.eye(3)\n",
    "E_rotate[:2, :2] = R\n",
    "print(f\"E_rotate:\\n{E_rotate}\")\n",
    "\n",
    "# Define the translation that moves the origin back.\n",
    "E_translate_back = np.eye(3)\n",
    "E_translate_back[:2,2] = c\n",
    "print(f\"E_translate_back:\\n{E_translate_back}\")\n",
    "\n",
    "# Compose the transformations to find the resulting similarity transform.\n",
    "S = E_translate_back @ E_rotate @ E_translate_to_centre\n",
    "print(f\"S:\\n{S}\")\n",
    "\n",
    "# Perform the transformation on the image.\n",
    "img_rotated = cv2.warpPerspective(img, S, img.shape[1::-1], flags=cv2.INTER_CUBIC)\n",
    "\n",
    "# Define a scaling/zooming\n",
    "scale = 0.75\n",
    "S_scale = np.eye(3)\n",
    "S_scale[:2, :2] *= scale\n",
    "print(f\"S_scale:\\n{S_scale}\")\n",
    "\n",
    "# Compose the transformation, including scaling:\n",
    "Sz = S_scale @ E_translate_back @ E_rotate @ E_translate_to_centre\n",
    "img_rotated_scaled = cv2.warpPerspective(img, Sz, img.shape[1::-1], flags=cv2.INTER_CUBIC)\n",
    "\n",
    "# Display the transformed and the scaled image\n",
    "axes = plt.subplots(1, 2)[1]\n",
    "ax1, ax2 = axes\n",
    "ax1.set_title('Rotated image')\n",
    "ax2.set_title('Rotated and scaled image')\n",
    "ax1.imshow(cv2.cvtColor(img_rotated, cv2.COLOR_BGR2RGB))\n",
    "ax2.imshow(cv2.cvtColor(img_rotated_scaled, cv2.COLOR_BGR2RGB))\n",
    "# remove the x and y ticks\n",
    "plt.setp(axes, xticks=[], yticks=[])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}